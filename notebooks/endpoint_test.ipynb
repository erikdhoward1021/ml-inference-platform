{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7426701",
   "metadata": {},
   "source": [
    "### Test Embedding Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbe9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ea806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(text):\n",
    "    url = \"http://localhost/predict\"\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\"text\": text}\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    return response.status_code, response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"One the endpoint is up and running, this request will return the status code (200) and the data \\\n",
    "    (a dictionary that includes the embeddings, dimensions, model version, and inference time in milliseconds).\"\n",
    "status_code, data = make_request(text_input)\n",
    "print(\"Status Code:\", status_code)\n",
    "print(\"Data:\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b6729",
   "metadata": {},
   "source": [
    "### Stress Test the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb61926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "URL = \"http://localhost/predict\"\n",
    "DATA = {\"text\": \"Small sentence to be embedded.\"}\n",
    "HEADERS = {\n",
    "'accept': 'application/json',\n",
    "'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "def call_inference(_):\n",
    "    try:\n",
    "        r = requests.post(URL, headers=HEADERS,json=DATA, timeout=5)\n",
    "        return r.status_code\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def stress_test(duration=60, concurrency=50):\n",
    "    end_time = time.time() + duration\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrency) as executor:\n",
    "        while time.time() < end_time:\n",
    "            futures = [executor.submit(call_inference, i) for i in range(concurrency)]\n",
    "            results = [f.result() for f in futures]\n",
    "            print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7344d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_test(duration=60, concurrency=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-inference-platform (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
